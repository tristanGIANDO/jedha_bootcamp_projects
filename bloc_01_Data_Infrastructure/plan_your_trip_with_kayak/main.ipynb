{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kayak](https://seekvectorlogo.com/wp-content/uploads/2018/01/kayak-vector-logo.png)\n",
    "\n",
    "# \"Plan your trip with Kayak\"\n",
    "## _Data Collection and Management Project_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le Projet\n",
    "\n",
    "L'équipe marketing de Kayak a découvert que 70 % de leurs utilisateurs qui planifient un voyage aimeraient avoir plus d'informations sur la destination vers laquelle ils se rendent.\n",
    "Par conséquent, l'équipe souhaite créer une application qui recommandera aux gens où planifier leurs prochaines vacances en se basant sur deux variables :\n",
    "* Météo\n",
    "* Hôtels dans la région\n",
    "\n",
    "Le projet débutant à peine, notre travail consiste à :\n",
    "* Récupérer les coordonnées GPS des destinations\n",
    "* Obtenir des données météorologiques pour chaque destination\n",
    "* Obtenir des informations sur les hôtels pour chaque destination\n",
    "* Stocker toutes les informations ci-dessus dans un _data lake_\n",
    "* Extraire, transformer et charger les données nettoyées du _data lake_ vers un _data warehouse_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Récupérer les données météo\n",
    "\n",
    "Grâce à `nominatim.streetmap.org`, nous allons pouvoir obtenir les coordonnées GPS d'une sélection de villes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(\"./.env\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous la liste des villes que l'équipe de Kayak veut analyser pour commencer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITIES =[\n",
    "    \"Mont Saint Michel\",\n",
    "    \"St Malo\",\n",
    "    \"Bayeux\",\n",
    "    \"Le Havre\",\n",
    "    \"Rouen\",\n",
    "    \"Paris\",\n",
    "    \"Amiens\",\n",
    "    \"Lille\",\n",
    "    \"Strasbourg\",\n",
    "    \"Chateau du Haut Koenigsbourg\",\n",
    "    \"Colmar\",\n",
    "    \"Eguisheim\",\n",
    "    \"Besancon\",\n",
    "    \"Dijon\",\n",
    "    \"Annecy\",\n",
    "    \"Grenoble\",\n",
    "    \"Lyon\",\n",
    "    \"Gorges du Verdon\",\n",
    "    \"Bormes les Mimosas\",\n",
    "    \"Cassis\",\n",
    "    \"Marseille\",\n",
    "    \"Aix en Provence\",\n",
    "    \"Avignon\",\n",
    "    \"Uzes\",\n",
    "    \"Nimes\",\n",
    "    \"Aigues Mortes\",\n",
    "    \"Saintes Maries de la mer\",\n",
    "    \"Collioure\",\n",
    "    \"Carcassonne\",\n",
    "    \"Ariege\",\n",
    "    \"Toulouse\",\n",
    "    \"Montauban\",\n",
    "    \"Biarritz\",\n",
    "    \"Bayonne\",\n",
    "    \"La Rochelle\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cities_coordinates(cities: list[str]) -> list[dict]:\n",
    "    url = \"https://nominatim.openstreetmap.org\"\n",
    "    endpoint = \"search\"\n",
    "    data = []\n",
    "    for city in cities:\n",
    "        city = city.lower()\n",
    "        payload = {\"city\": city, \"format\": \"json\"}\n",
    "        response = requests.get(f\"{url}/{endpoint}\", params=payload)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed with '{city}' -> {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        resp = response.json()[0]\n",
    "        data.append({\"city\": city,\n",
    "                        \"lat\": resp.get(\"lat\", None),\n",
    "                        \"lon\": resp.get(\"lon\", None)})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toujours via `requests`, nous allons cette fois-ci récupérer des données sur la météo à venir dans une sélection de villes.\n",
    "\n",
    "Pour cela, utilisons l'API `openweathermap.org`. La stratégie reste la même si ce n'est que cette API a besoin d'une API KEY pour executer des requêtes.\n",
    "\n",
    "Nous avons décidé de récupérer les données météorologiques des 7 jours à venir.\n",
    "Le but est de déterminer dans quelles villes le temps sera le plus agréable.\n",
    "Pour cela, nous allons nous baser sur ces éléments :\n",
    "* la température minimum (`temp_min`)\n",
    "* la température maximum (`temp_max`)\n",
    "* le pourcentage d'humidité (`humidity`)\n",
    "* le pourcentage de couverture nuageuse (`clouds`)\n",
    "* la probabilité qu'il pleuve (`rain_prob`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(cities_coordinates: list[dict]) -> list[dict]:\n",
    "    url = \"https://api.openweathermap.org/data/2.5\"\n",
    "    endpoint = \"forecast\"\n",
    "    data = []\n",
    "    city_id = 1\n",
    "    for row in cities_coordinates.copy():\n",
    "        payload = {\"lat\": float(row[\"lat\"]),\n",
    "                    \"lon\": float(row[\"lon\"]),\n",
    "                    \"units\": \"metric\",\n",
    "                    \"cnt\": 7,  # 7 days to come\n",
    "                    \"appid\": os.getenv(\"WEATHER_KEY\")}\n",
    "\n",
    "        response = requests.get(f\"{url}/{endpoint}\",\n",
    "                                params=payload)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed -> {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        day_id = 1\n",
    "        for dt in response.json()[\"list\"]:\n",
    "            data.append({\n",
    "                \"city_id\": city_id,\n",
    "                \"city\": row[\"city\"],\n",
    "                \"lat\": float(row[\"lat\"]),\n",
    "                \"lon\": float(row[\"lon\"]),\n",
    "                \"day_id\": day_id,\n",
    "                \"temp\": dt[\"main\"].get(\"temp\", None),\n",
    "                \"temp_min\": dt[\"main\"].get(\"temp_min\", None),\n",
    "                \"temp_max\": dt[\"main\"].get(\"temp_max\", None),\n",
    "                \"humidity\": dt[\"main\"].get(\"humidity\", None),\n",
    "                \"clouds\": dt[\"clouds\"].get(\"all\", None),\n",
    "                \"rain_prob\": dt.get(\"pop\", None),\n",
    "            })\n",
    "            day_id += 1\n",
    "        city_id += 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que les fonctions sont écrites, il n'y a plus qu'à enregistrer le résultat dans un fichier CSV !\n",
    "_(Pour des raisons de gains de place, les conventions PEP8 ne sont pas respectées dans la cellule ci-dessous)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(get_weather_data(get_cities_coordinates(CITIES)))\n",
    "df.to_csv(\"weather_data.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Récupérer les données sur les hôtels\n",
    "\n",
    "Le client veut se baser sur le site booking.com pour collecter ses données. Comme il n'y a pas d'API officielle, il va falloir faire du web scraping pour obtenir les informations dont nous avons besoin.\n",
    "\n",
    "Nous avons donc simulé une recherche sur le site et récupéré tous les hôtels proposés grâce au CSS.\n",
    "Après avoir stocké leur nom, note, et adresse URL, nous avons simulé un clic sur les hôtels pour accéder à leurs détails (voir méthode `self.parse_hotel_detail`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class BookingSpider(scrapy.Spider):\n",
    "    name = \"booking\"\n",
    "    allowed_domains = [\"booking.com\"]\n",
    "    cities = [\"montpellier\"]\n",
    "    start_urls = [f\"https://www.booking.com/searchresults.html?ss={city}\" for city in CITIES]\n",
    "\n",
    "    custom_settings = {\n",
    "        \"USER_AGENT\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"ROBOTSTXT_OBEY\": False\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        hotels = response.css('div[data-testid=\"property-card\"]')\n",
    "\n",
    "        for hotel in hotels:\n",
    "            city = response.url.split(\"=\")[-1]\n",
    "            name = hotel.css('div[data-testid=\"title\"]::text').get().strip()\n",
    "            rating = hotel.css(\"div.f13857cc8c.e008572b71::text\").get()\n",
    "            if not rating:\n",
    "                rating = \"0.0\"\n",
    "            url = hotel.css('a[data-testid=\"title-link\"]::attr(href)').get()\n",
    "\n",
    "            yield response.follow(url, callback=self.parse_hotel_detail,\n",
    "                                  meta={\"name\": name,\n",
    "                                        \"rating\": rating,\n",
    "                                        \"city\": city\n",
    "                                        })\n",
    "\n",
    "        next_page = response.css(\"a.bui-pagination__link.pagenext::attr(href)\").get()\n",
    "        if next_page:\n",
    "            yield response.follow(next_page, self.parse)\n",
    "\n",
    "    def parse_hotel_detail(self, response):\n",
    "        city = response.meta[\"city\"]\n",
    "        name = response.meta[\"name\"]\n",
    "        url = response.url\n",
    "        rating = response.meta[\"rating\"]\n",
    "        address = response.css(\"span.hp_address_subtitle.js-hp_address_subtitle.jq_tooltip::text\").get().strip()\n",
    "        description = response.css('p[data-testid=\"property-description\"]::text').get().strip()\n",
    "        coordinates = response.css(\"a#hotel_address::attr(data-atlas-latlng)\").get()\n",
    "\n",
    "        if coordinates:\n",
    "            latitude, longitude = coordinates.split(\",\")\n",
    "            latitude = float(latitude)\n",
    "            longitude = float(longitude)\n",
    "        else:\n",
    "            latitude = None\n",
    "            longitude = None\n",
    "\n",
    "        yield {\n",
    "            \"city\": city,\n",
    "            \"name\": name,\n",
    "            \"url\": url,\n",
    "            \"rating\": rating,\n",
    "            \"address\": address,\n",
    "            \"description\": description,\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons stocké les données dans un fichier JSON, il faut donc les convertir en CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hotels.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    hotel_content = file.read()\n",
    "\n",
    "df = pd.DataFrame(eval(hotel_content))\n",
    "df.to_csv(\"csv_files/weather_data.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
